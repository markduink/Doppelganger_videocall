{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DoppelGanger Video Call Generative Artwork\n",
        "\n",
        ": Meet your doppelganger"
      ],
      "metadata": {
        "id": "8DHymSIZ14Bo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DOWNLOAD E4E AND LOAD"
      ],
      "metadata": {
        "id": "XKtXb064WlF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5odXQt6cWkhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/encoder4editing"
      ],
      "metadata": {
        "id": "7JZA0NkvefNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/omertov/encoder4editing.git /content/encoder4editing\n"
      ],
      "metadata": {
        "id": "OzOzlrstwqSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/e4e_ffhq_encode.pt\" \"/content/encoder4editing/e4e_ffhq.pt\"\n"
      ],
      "metadata": {
        "id": "q7sj3uvXWZCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if model is downloaded\n",
        "\n",
        "!ls -lh /content/encoder4editing/e4e_ffhq.pt"
      ],
      "metadata": {
        "id": "lWMX-TTqWaXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure Ninja is installed for PyTorch C++ extensions\n",
        "!pip install ninja --quiet\n",
        "import os\n",
        "os.environ['TORCH_EXTENSIONS_DIR'] = '/root/.cache/torch_extensions'\n",
        "\n",
        "# Optional: clear corrupted builds (just in case)\n",
        "!rm -rf /root/.cache/torch_extensions\n"
      ],
      "metadata": {
        "id": "E1W7QqQD1EMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "import torch\n",
        "import sys\n",
        "sys.path.append('/content/encoder4editing')\n",
        "\n",
        "from models.psp import pSp\n",
        "\n",
        "# Load the checkpoint\n",
        "ckpt_path = \"/content/encoder4editing/e4e_ffhq.pt\"\n",
        "ckpt = torch.load(ckpt_path, map_location='cuda')\n",
        "opts = ckpt['opts']\n",
        "opts['checkpoint_path'] = ckpt_path\n",
        "opts = Namespace(**opts)\n",
        "\n",
        "# Initialize and load the network\n",
        "net = pSp(opts)\n",
        "net.eval().cuda()\n",
        "\n",
        "print(\"✅ e4e model loaded!\")\n"
      ],
      "metadata": {
        "id": "UiB7DXgjTp_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# optional: TEST THE MODEL UPLOAD A PHOTO OF YOUR FACE"
      ],
      "metadata": {
        "id": "x1ltbYsTWOfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install face_recognition (quietly)\n",
        "!pip install face_recognition --quiet\n",
        "\n",
        "# Upload an image from local\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Import required libraries\n",
        "import face_recognition\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Automatically get uploaded filename\n",
        "input_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Load image\n",
        "img = face_recognition.load_image_file(input_path)\n",
        "face_locations = face_recognition.face_locations(img)\n",
        "\n",
        "# Check for face\n",
        "if not face_locations:\n",
        "    raise ValueError(\" No face detected! Try uploading a clear image.\")\n",
        "\n",
        "# Crop the first face found\n",
        "top, right, bottom, left = face_locations[0]\n",
        "face_crop = img[top:bottom, left:right]\n",
        "face_image = Image.fromarray(face_crop)\n",
        "\n",
        "# Optional: show cropped face\n",
        "plt.imshow(face_image)\n",
        "plt.title(\"Detected & Cropped Face\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Preprocess for e4e\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "])\n",
        "\n",
        "img_tensor = transform(face_image).unsqueeze(0).cuda()\n",
        "\n",
        "# Encode into latent space\n",
        "with torch.no_grad():\n",
        "    latent = net.encoder(img_tensor)\n",
        "\n",
        "print(\"✅ Face uploaded, cropped, and encoded into latent space!\")\n"
      ],
      "metadata": {
        "id": "GoTmqQZKT-Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "# Decode latent into image\n",
        "with torch.no_grad():\n",
        "    generated_image, _ = net.decoder(latent)\n",
        "\n",
        "# Normalize from [-1, 1] to [0, 1]\n",
        "generated_image = (generated_image + 1) / 2\n",
        "\n",
        "# Save and display\n",
        "save_image(generated_image, 'reconstructed_face.png')\n",
        "\n",
        "from IPython.display import Image as IPyImage, display\n",
        "display(IPyImage('reconstructed_face.png'))\n",
        "\n"
      ],
      "metadata": {
        "id": "Tu2xxqHEVISp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version 1, This will give you a new face every 1 second, run this and copy the code into the script from here https://github.com/markduink/Doppelganger_videocall"
      ],
      "metadata": {
        "id": "XXyRXuViyMP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔧 Install required packages\n",
        "!pip install flask flask_cors pyngrok face-recognition\n",
        "\n",
        "from flask import Flask, request, jsonify, make_response\n",
        "from flask_cors import CORS\n",
        "import numpy as np\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import face_recognition\n",
        "import threading\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "CORS(app, origins=[\"https://markduink.github.io\"])  # Only allow GitHub Pages\n",
        "\n",
        "# 🔄 Ensure model `net` is already loaded\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "def apply_e4e(image):\n",
        "    img_np = np.array(image)\n",
        "    face_locations = face_recognition.face_locations(img_np)\n",
        "    if not face_locations:\n",
        "        raise ValueError(\"No face detected.\")\n",
        "\n",
        "    top, right, bottom, left = face_locations[0]\n",
        "    face_crop = image.crop((left, top, right, bottom))\n",
        "    aligned = transform(face_crop).unsqueeze(0).cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        latent = net.encoder(aligned)\n",
        "        generated_image, _ = net.decoder(latent)\n",
        "\n",
        "    generated_image = (generated_image + 1) / 2\n",
        "    if generated_image.dim() == 4:\n",
        "        generated_image = generated_image[0]\n",
        "    generated_image = generated_image.permute(1, 2, 0).cpu().numpy()\n",
        "    generated_image = (generated_image * 255).astype(np.uint8)\n",
        "    return Image.fromarray(generated_image)\n",
        "\n",
        "@app.route('/process', methods=['POST', 'OPTIONS'])\n",
        "def process_image():\n",
        "    if request.method == 'OPTIONS':\n",
        "        response = make_response()\n",
        "        response.headers['Access-Control-Allow-Origin'] = 'https://markduink.github.io'\n",
        "        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'\n",
        "        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'\n",
        "        return response\n",
        "\n",
        "    try:\n",
        "        data = request.json['image']\n",
        "        image_bytes = base64.b64decode(data)\n",
        "        image = Image.open(BytesIO(image_bytes)).convert('RGB')\n",
        "        transformed = apply_e4e(image)\n",
        "\n",
        "        buffer = BytesIO()\n",
        "        transformed.save(buffer, format=\"JPEG\")\n",
        "        encoded_result = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
        "\n",
        "        response = make_response(jsonify({'image': encoded_result}))\n",
        "        response.headers['Access-Control-Allow-Origin'] = 'https://markduink.github.io'\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        response = make_response(jsonify({'error': str(e)}), 400)\n",
        "        response.headers['Access-Control-Allow-Origin'] = 'https://markduink.github.io'\n",
        "        return response\n",
        "\n",
        "# Run Flask in thread\n",
        "def run_flask():\n",
        "    try:\n",
        "        app.run(host='0.0.0.0', port=5000)\n",
        "    except OSError:\n",
        "        print(\"⚠️ Port 5000 already in use, skipping.\")\n",
        "\n",
        "threading.Thread(target=run_flask, daemon=True).start()\n",
        "\n",
        "# Expose via ngrok\n",
        "!pkill -f ngrok\n",
        "!ngrok authtoken 2ubEflxgxaWcUp773o7osK572FR_85fsgXR1Zb79KekWMAp3D  # Replace with your actual ngrok token\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(\"🚀 Your backend URL is:\", public_url + \"/process\")\n"
      ],
      "metadata": {
        "id": "ZwSi7IOgc-81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version 2, This will loop in the latent space giving you a animated face doppelganger , run this and copy the link provided into the java script from here https://github.com/markduink/Doppelganger_videocall"
      ],
      "metadata": {
        "id": "E66YEgUe2F41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install flask flask_cors pyngrok face-recognition\n",
        "\n",
        "from flask import Flask, request, jsonify, make_response\n",
        "from flask_cors import CORS\n",
        "import numpy as np\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import face_recognition\n",
        "import threading\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "CORS(app, origins=[\"https://markduink.github.io\"])\n",
        "\n",
        "# Ensure model `net` is already loaded\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Interpolation state (preserved across frames)\n",
        "interpolation_state = {\n",
        "    \"latent_start\": None,\n",
        "    \"latent_end\": None,\n",
        "    \"alpha\": 0.0,\n",
        "    \"step\": 0.05\n",
        "}\n",
        "\n",
        "def interpolate_latents(start, end, alpha):\n",
        "    return (1 - alpha) * start + alpha * end\n",
        "\n",
        "def apply_e4e_looped(image):\n",
        "    img_np = np.array(image)\n",
        "    face_locations = face_recognition.face_locations(img_np)\n",
        "    if not face_locations:\n",
        "        raise ValueError(\"No face detected.\")\n",
        "\n",
        "    top, right, bottom, left = face_locations[0]\n",
        "    face_crop = image.crop((left, top, right, bottom))\n",
        "    aligned = transform(face_crop).unsqueeze(0).cuda()\n",
        "\n",
        "    # Update interpolation\n",
        "    with torch.no_grad():\n",
        "        if interpolation_state[\"latent_start\"] is None:\n",
        "            interpolation_state[\"latent_start\"] = net.encoder(aligned)\n",
        "            interpolation_state[\"latent_end\"] = torch.randn_like(interpolation_state[\"latent_start\"])\n",
        "\n",
        "        alpha = interpolation_state[\"alpha\"]\n",
        "        interpolated_latent = interpolate_latents(interpolation_state[\"latent_start\"], interpolation_state[\"latent_end\"], alpha)\n",
        "\n",
        "        # Advance alpha\n",
        "        interpolation_state[\"alpha\"] += interpolation_state[\"step\"]\n",
        "        if interpolation_state[\"alpha\"] >= 1.0:\n",
        "            interpolation_state[\"alpha\"] = 0.0\n",
        "            interpolation_state[\"latent_start\"] = interpolated_latent\n",
        "            interpolation_state[\"latent_end\"] = torch.randn_like(interpolated_latent)\n",
        "\n",
        "        generated_image, _ = net.decoder(interpolated_latent)\n",
        "\n",
        "    generated_image = (generated_image + 1) / 2\n",
        "    if generated_image.dim() == 4:\n",
        "        generated_image = generated_image[0]\n",
        "    generated_image = generated_image.permute(1, 2, 0).cpu().numpy()\n",
        "    generated_image = (generated_image * 255).astype(np.uint8)\n",
        "    return Image.fromarray(generated_image)\n",
        "\n",
        "@app.route('/process', methods=['POST', 'OPTIONS'])\n",
        "def process_image():\n",
        "    if request.method == 'OPTIONS':\n",
        "        response = make_response()\n",
        "        response.headers['Access-Control-Allow-Origin'] = 'https://markduink.github.io'\n",
        "        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'\n",
        "        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'\n",
        "        return response\n",
        "\n",
        "    try:\n",
        "        data = request.json['image']\n",
        "        image_bytes = base64.b64decode(data)\n",
        "        image = Image.open(BytesIO(image_bytes)).convert('RGB')\n",
        "        transformed = apply_e4e_looped(image)\n",
        "\n",
        "        buffer = BytesIO()\n",
        "        transformed.save(buffer, format=\"JPEG\")\n",
        "        encoded_result = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
        "\n",
        "        response = make_response(jsonify({'image': encoded_result}))\n",
        "        response.headers['Access-Control-Allow-Origin'] = 'https://markduink.github.io'\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        response = make_response(jsonify({'error': str(e)}), 400)\n",
        "        response.headers['Access-Control-Allow-Origin'] = 'https://markduink.github.io'\n",
        "        return response\n",
        "\n",
        "# Run Flask in thread\n",
        "def run_flask():\n",
        "    try:\n",
        "        app.run(host='0.0.0.0', port=5000)\n",
        "    except OSError:\n",
        "        print(\"⚠️ Port 5000 already in use, skipping.\")\n",
        "\n",
        "threading.Thread(target=run_flask, daemon=True).start()\n",
        "\n",
        "# Expose via ngrok\n",
        "!pkill -f ngrok\n",
        "!ngrok authtoken 2ubEflxgxaWcUp773o7osK572FR_85fsgXR1Zb79KekWMAp3D\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(\"🚀 Your backend URL is:\", public_url + \"/process\")\n"
      ],
      "metadata": {
        "id": "BMpoedUft9rP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}